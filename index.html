<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

    <title>KyoungJin Oh</title>

    <meta name="author" content="KyoungJin Oh" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon" />
    <link rel="stylesheet" type="text/css" href="stylesheet.css" />
  </head>

  <body>
    <table
      style="
        width: 100%;
        max-width: 800px;
        border: 0px;
        border-spacing: 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
      "
    >
      <tbody>
        <tr style="padding: 0px">
          <td style="padding: 0px">
            <table
              class="section-card"
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr style="padding: 0px">
                  <td style="padding: 2.5%; width: 63%; vertical-align: middle">
                    <p class="name" style="text-align: center">KyoungJin Oh</p>
                    <p>
                      I am an undergraduate student in Computer Science and Engineering at
                      <a href="https://www.yonsei.ac.kr/">Yonsei University</a>. Currently, I am a research intern at
                      the <a href="https://cvlab.kaist.ac.kr/">KAIST Computer Vision Lab (CVLAB)</a>, where I contribute
                      to the image and video restoration team. <br />
                      I aspire to become an impactful researcher by producing work that is broadly applicable across
                      various sub-fields of Computer Vision.
                    </p>
                    <p style="text-align: center">
                      <a href="mailto:2364ohkj@yonsei.ac.kr">Email</a>
                      &nbsp;/&nbsp;
                      <a href="data/KyoungJinOhCV.pdf">CV</a> &nbsp;/&nbsp;
                      <a href="https://github.com/2364ohkj/">Github</a>
                    </p>
                  </td>
                  <td style="padding: 2.5%; width: 37%; max-width: 37%">
                    <img
                      style="width: 100%; max-width: 100%; object-fit: cover; border-radius: 50%"
                      alt="profile photo"
                      src="images/KyoungJinOh.jpg"
                      class="hoverZoomLink"
                    />
                  </td>
                </tr>
              </tbody>
            </table>

            <table
              class="section-card"
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr>
                  <td style="padding: 16px; width: 100%; vertical-align: middle">
                    <h2>Research Interests</h2>
                    <p>
                      I have a broad interest in various fields of Computer Vision. Currently, as a member of the
                      restoration team, I have been conducting research in this area. Recently, I studied
                      <b><a href="https://cvlab-kaist.github.io/TAIR/">Text-Aware Image Restoration (TAIR)</a></b
                      >, a new task focused on restoring both visual quality and text fidelity in degraded images.
                      Building on this, I am currently studying <b>video restoration using optical flow</b>. In the
                      future, I plan to delve into <b>diffusion guidance</b>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table
              class="section-card"
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr>
                  <td style="padding: 16px; width: 100%; vertical-align: middle">
                    <h2>Research Experience</h2>
                    <a href="https://cvlab.kaist.ac.kr/">
                      <h3>CVLAB, KAIST</h3>
                    </a>
                    <em>Jun 2025 – Present</em>
                    <ul>
                      <li>Advisor: Prof. Seungryong Kim</li>
                      <li>Image & Video Restoration</li>
                    </ul>
                    <a href="https://www.ciplab.kr/">
                      <h3>CIPLAB, Yonsei</h3>
                    </a>
                    <em>Jan 2025 – Mar 2025</em>
                    <ul>
                      <li>Advisor: Prof. Seonjoo Kim</li>
                      <li>Metrics for diffusion models</li>
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>

            <table
              class="section-card"
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr>
                  <td style="padding: 16px; width: 100%; vertical-align: middle">
                    <h2>Education</h2>
                    <a href="https://www.yonsei.ac.kr/"><h3>Yonsei University</h3></a>
                    <ul>
                      <li><b>B.S. of Computer Science and Engineering</b> <br /><em>Mar 2022 - Present</em></li>
                      <br />
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>

            <table
              class="section-card"
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr>
                  <td style="padding: 16px; width: 100%; vertical-align: middle">
                    <h2>Honors & Awards</h2>
                    <p>High Honors: Top 3%; Honors: Top 10% of the cohort</p>
                    <ul>
                      <li>
                        <b>Honors</b> <br />
                        <small><em>Awarded by Yonsei university</em>, 2nd semester of 2023</small>
                      </li>
                      <br />
                      <li>
                        <b>Silver Prize, The 1st Yonsei GenAI Contest</b> <br />
                        <small><b>KyoungJin Oh</b>, JunSeong Lee, KangWon Lee</small> <br />
                        <small><em>Awarded by Yonsei University SW-Centered University Program</em>, Dec 2023</small>
                        <p>
                          We developed web-based software using the OpenAI API. The software takes an artwork as input
                          and outputs the appropriate lighting for the exhibition and how the artwork would appear when
                          displayed in the exhibition under that lighting.
                        </p>
                      </li>
                      <br />
                      <li>
                        <b>High Honors</b> <br /><small>
                          <em>Awarded by Yonsei university</em>, 1st semester of 2023</small
                        >
                      </li>
                      <br />
                      <li>
                        <b>Honors</b> <br />
                        <small><em>Awarded by Yonsei university</em>, 1st semester of 2022</small>
                      </li>
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>

            <table
              class="section-card"
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px 10px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr>
                  <td colspan="2">
                    <h2>Course Projects</h2>
                    <!--
                      <p>
                        I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my
                        research is about inferring the physical world (shape, motion, color, light, etc) from images,
                        usually with radiance fields. Some papers are
                        <span class="highlight">highlighted</span>.
                      </p>
                    -->
                  </td>
                </tr>
                <!--
                  <tr bgcolor="#fffdf0">
                    <td style="padding: 16px; width: 20%; vertical-align: middle">
                      <img
                        src="images/image_denoising.png"
                        alt="image_denoising"
                        width="160"
                        style="border-style: none"
                      />
                    </td>
                    <td style="padding: 8px; width: 80%; vertical-align: middle">
                      <a href="https://szymanowiczs.github.io/bolt3d">
                        <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
                      </a>
                      <br />
                      <a href="https://szymanowiczs.github.io/">Stanislaw Szymanowicz</a>,
                      <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
                      <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
                      <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
                      <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
                      <a href="https://holynski.org">Aleksander Holynski</a>,
                      <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://henzler.github.io">Philipp Henzler</a>
                      <br />
                      <em>ICCV</em>, 2025
                      <br />
                      <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
                      /
                      <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
                      <p></p>
                      <p>
                        By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on
                        a single GPU) feed-forward 3D scene generation.
                      </p>
                    </td>
                  </tr>
                -->

                <tr bgcolor="#fffdf0">
                  <td style="padding: 16px; width: 20%; vertical-align: middle">
                    <img
                      src="images/image_denoising.png"
                      alt="image_denoising"
                      width="160"
                      style="border-style: none"
                    />
                  </td>
                  <td style="padding: 8px; width: 80%; vertical-align: middle">
                    <a href="https://github.com/2364ohkj/CAS3116_ComputerVision/tree/main/2022148070_project1">
                      <span class="papertitle">Image Denoising</span></a
                    >
                    <br />
                    <em>CAS3116 Computer Vision</em>, 2025
                    <br />
                    <a href="https://github.com/2364ohkj/CAS3116_ComputerVision/tree/main/2022148070_project1"
                      >project page</a
                    >
                    <p></p>
                    <p>
                      I implemented image filters in both the spatial and frequency domains to restore noisy images. I
                      manually built spatial filters like Gaussian and Laplacian via convolution, and also implemented
                      frequency filters using Fourier transforms, ultimately synthesizing these techniques for practical
                      image denoising.
                    </p>
                  </td>
                </tr>
                <tr bgcolor="#fffdf0">
                  <td style="padding: 16px; width: 20%; vertical-align: middle">
                    <img
                      src="images/face_recognition.png"
                      alt="face_recognition"
                      width="160"
                      style="border-style: none"
                    />
                  </td>
                  <td style="padding: 8px; width: 80%; vertical-align: middle">
                    <a href="https://github.com/2364ohkj/CAS3116_ComputerVision/tree/main/2022148070_project2/task1">
                      <span class="papertitle">PCA-based Face Recognition</span></a
                    >
                    <br />
                    <em>CAS3116 Computer Vision</em>, 2025
                    <br />
                    <a href="https://github.com/2364ohkj/CAS3116_ComputerVision/tree/main/2022148070_project2/task1"
                      >project page</a
                    >
                    <p></p>
                    <p>
                      I used PCA with SVD to extract Eigenfaces (principal components) for Face Recognition. The
                      required number of components was determined by a cumulative variance threshold. Face images were
                      reconstructed by projecting them onto the PCA basis. Final classification utilized the nearest
                      neighbor algorithm to match test images in the PCA space via Euclidean distance.
                    </p>
                  </td>
                </tr>
                <tr bgcolor="#fffdf0">
                  <td style="padding: 16px; width: 20%; vertical-align: middle">
                    <img
                      src="images/image_stitching.jpg"
                      alt="image_stitching"
                      width="160"
                      style="border-style: none"
                    />
                  </td>
                  <td style="padding: 8px; width: 80%; vertical-align: middle">
                    <a href="https://github.com/2364ohkj/CAS3116_ComputerVision/tree/main/2022148070_project2/task2">
                      <span class="papertitle"> Homography Estimation and Image Stitching</span>
                    </a>
                    <br />
                    <em>CAS3116 Computer Vision</em>, 2025
                    <br />
                    <a href="https://github.com/2364ohkj/CAS3116_ComputerVision/tree/main/2022148070_project2/task2"
                      >project page</a
                    >
                    <p></p>
                    <p>
                      Homography matrix H was estimated from correspondence points by applying SVD to Matrix A. RANSAC
                      was used for robust estimation to maximize inliers (points within an error threshold). Using more
                      correspondences increased the method's robustness. The main limitation is the violation of the
                      planarity assumption in 3D scenes, which causes artifacts due to parallax.
                    </p>
                  </td>
                </tr>
                <tr bgcolor="#fffdf0">
                  <td style="padding: 16px; width: 20%; vertical-align: middle">
                    <img
                      src="images/sentiment_classification.webp"
                      alt="sentiment_classification"
                      width="160"
                      style="border-style: none"
                    />
                  </td>
                  <td style="padding: 8px; width: 80%; vertical-align: middle">
                    <a
                      href="https://github.com/2364ohkj/AAI3201_TheoryAndPracticeOfDeepLearning/tree/main/final_project"
                    >
                      <span class="papertitle">Sentiment Classification in Korean using NLLB and ROBERTA</span>
                    </a>
                    <br />
                    <em>AAI3201 Theory & Practice of Deep Learning</em>, 2024
                    <br />
                    <a
                      href="https://github.com/2364ohkj/AAI3201_TheoryAndPracticeOfDeepLearning/tree/main/final_project"
                      >project page</a
                    >
                    <p></p>
                    <p>
                      This project proposed a method for Sentiment Classification of Korean sentences by sequentially
                      using the NLLB-200-3.3B (NLLB) model to translate Korean into English and the English sentiment
                      analysis model, twitter-roberta-base-sentiment-latest (ROBERTa). The proposed model achieved an
                      Accuracy of 0.7859, demonstrating better performance than the comparison model,
                      bert-base-cased-Korean-sentiment, which scored 0.7247.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table
              class="section-card"
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px 10px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr>
                  <td colspan="2">
                    <h2>Extracurricular Activities</h2>
                  </td>
                </tr>
                <tr bgcolor="#fffdf0">
                  <td style="padding: 16px; width: 20%; vertical-align: middle">
                    <img src="images/UNID.png" alt="UNID" width="160" style="border-style: none" />
                  </td>
                  <td style="padding: 8px; width: 80%; vertical-align: middle">
                    <a href="https://aiconnect.kr/competition/detail/236">
                      <span class="papertitle">UNID-THON Management</span></a
                    >
                    <br />
                    Apr 2023 – Nov 2023
                    <br />
                    <p>
                      As the Vice President of Uni-D, I planned and executed key aspects of Uni-DTHON—a hackathon and
                      datathon competition organized by Uni-D, an organization formed by the student councils of various
                      university computer science departments—which included theme development, data curation, and venue
                      selection.
                    </p>
                  </td>
                </tr>

                <tr bgcolor="#fffdf0">
                  <td style="padding: 16px; width: 20%; vertical-align: middle">
                    <img src="images/StudentCouncil.jpg" alt="Student Council" width="160" style="border-style: none" />
                  </td>
                  <td style="padding: 8px; width: 80%; vertical-align: middle">
                    <span class="papertitle">Student Council</span>
                    <br />
                    Mar 2023 – Dec 2023
                    <br />
                    <p>
                      As the President of the Student Council for the Department of Computer Science and Engineering, I
                      managed and administered various department events. Furthermore, I effectively collaborated with
                      diverse individuals, building effective relationships throughout this role.
                    </p>
                  </td>
                </tr>
                <tr bgcolor="#fffdf0">
                  <td style="padding: 16px; width: 20%; vertical-align: middle">
                    <img src="images/FCYonsei.jpg" alt="FCYonsei" width="160" style="border-style: none" />
                  </td>
                  <td style="padding: 8px; width: 80%; vertical-align: middle">
                    <span class="papertitle">FC Yonsei Soccer Club</span>
                    <br />
                    Mar 2022 – Present
                    <br />
                    <p>
                      I competed in events such as K7, SUFA, and the Yonsei University President’s Cup. Through
                      participating in multiple matches, I developed teamwork skills.
                    </p>
                  </td>
                </tr>
                <tr bgcolor="#fffdf0">
                  <td style="padding: 16px; width: 20%; vertical-align: middle">
                    <img src="images/INSIDERS.jpeg" alt="INSIDERS" width="160" style="border-style: none" />
                  </td>
                  <td style="padding: 8px; width: 80%; vertical-align: middle">
                    <a href="https://www.insiders.co.kr/"> <span class="papertitle">INSIDERS Startup Society</span></a>
                    <br />
                    Mar 2022 – Aug 2022
                    <br />
                    <p>
                      I learned how to generate and develop business ideas in the entrepreneurial space through projects
                      like international startup benchmarking, and contributed to a project aimed at developing a new 3D
                      modeling tool program as an Minimum Viable Product (MVP).
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr>
                  <td style="padding: 0px">
                    <br />
                    <p style="text-align: right; font-size: small">
                      Using <a href="https://jonbarron.info/">Jon Barron’s template</a>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
